import json
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings

# Ignorer les avertissements
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning)
warnings.filterwarnings("ignore", category=UserWarning)

def evaluate_models_for_nature(nature_id, data_file):
    """
    Ã‰value tous les modÃ¨les de rÃ©gression pour une nature donnÃ©e
    """
    try:
        # Charger les donnÃ©es
        with open(data_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        if not data:
            print(f"âš ï¸  Aucune donnÃ©e trouvÃ©e pour nature_{nature_id}")
            return None
        
        df = pd.DataFrame(data)
        
        # Filtrer les donnÃ©es avec montant valide
        df = df[df['montant'].notna() & (df['montant'] > 0)]
        
        if len(df) < 10:
            print(f"âš ï¸  Pas assez de donnÃ©es pour nature_{nature_id} (seulement {len(df)} entrÃ©es)")
            return None
        
        # CrÃ©er le champ textuel combinÃ©
        df["text"] = df["reference"].fillna("") + " " + df["objet"].fillna("") + " " + df["acheteur"].fillna("")
        
        # DÃ©finir X et y
        X = df["text"]
        y = df["montant"]
        
        # SÃ©parer les donnÃ©es
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        
        # DÃ©finir les modÃ¨les
        models = {
            "Linear Regression": LinearRegression(),
            "Ridge Regression": Ridge(),
            "Lasso Regression": Lasso(),
            "Decision Tree": DecisionTreeRegressor(),
            "Random Forest": RandomForestRegressor(),
            "Gradient Boosting": GradientBoostingRegressor(),
            "Extra Trees": ExtraTreesRegressor(),
            "K-Nearest Neighbors": KNeighborsRegressor(n_neighbors=min(3, len(X_train))),
            "Support Vector Regressor": SVR(),
            "MLP Regressor": MLPRegressor(max_iter=500)
        }
        
        # TF-IDF vectorizer
        vectorizer = TfidfVectorizer(max_features=1000)
        
        # Ã‰valuer chaque modÃ¨le
        results = []
        
        for name, model in models.items():
            pipeline = Pipeline([
                ("tfidf", vectorizer),
                ("regressor", model)
            ])
            try:
                pipeline.fit(X_train, y_train)
                y_pred = pipeline.predict(X_test)
                
                mae = mean_absolute_error(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                r2 = r2_score(y_test, y_pred)
                
                results.append({
                    "Model": name,
                    "MAE": round(mae, 2),
                    "RMSE": round(rmse, 2),
                    "RÂ² Score": round(r2, 4)
                })
            except Exception as e:
                results.append({
                    "Model": name,
                    "MAE": None,
                    "RMSE": None,
                    "RÂ² Score": None,
                    "Error": str(e)
                })
        
        # CrÃ©er le DataFrame des rÃ©sultats
        results_df = pd.DataFrame(results).sort_values(by="RMSE", na_position="last").reset_index(drop=True)
        
        # Ajouter des mÃ©tadonnÃ©es
        results_df["Nature_ID"] = nature_id
        results_df["Total_Data"] = len(df)
        results_df["Train_Size"] = len(X_train)
        results_df["Test_Size"] = len(X_test)
        
        return results_df
        
    except Exception as e:
        print(f"âŒ Erreur pour nature_{nature_id}: {e}")
        return None

def process_all_natures():
    """
    Traite toutes les natures et gÃ©nÃ¨re les rÃ©sultats de rÃ©gression
    """
    base_dir = Path(".")
    all_results = []
    processed_count = 0
    error_count = 0
    
    print("ðŸ” Ã‰valuation des modÃ¨les de rÃ©gression pour toutes les natures...")
    
    # Parcourir tous les dossiers nature_
    for item in base_dir.iterdir():
        if item.is_dir() and item.name.startswith("nature_"):
            nature_id = item.name.replace("nature_", "")
            
            # Chercher le fichier attributed_cleaned.json
            data_file = item / "data" / "attributed_cleaned.json"
            
            if not data_file.exists():
                print(f"âš ï¸  Fichier non trouvÃ© pour nature_{nature_id}: {data_file}")
                error_count += 1
                continue
            
            print(f"ðŸ“ Traitement de nature_{nature_id}...")
            
            # Ã‰valuer les modÃ¨les pour cette nature
            results_df = evaluate_models_for_nature(nature_id, data_file)
            
            if results_df is not None:
                # Sauvegarder les rÃ©sultats pour cette nature
                output_file = item / "regression_results.json"
                results_df.to_json(output_file, orient="records", indent=2, force_ascii=False)
                
                # Ajouter Ã  la liste globale
                all_results.append(results_df)
                processed_count += 1
                
                print(f"   âœ… {len(results_df)} modÃ¨les Ã©valuÃ©s, donnÃ©es sauvegardÃ©es")
                
                # Afficher le meilleur modÃ¨le
                best_model = results_df.iloc[0]
                print(f"   ðŸ† Meilleur modÃ¨le: {best_model['Model']} (RMSE: {best_model['RMSE']})")
            else:
                error_count += 1
    
    # Combiner tous les rÃ©sultats
    if all_results:
        combined_results = pd.concat(all_results, ignore_index=True)
        
        # Sauvegarder les rÃ©sultats combinÃ©s
        combined_results.to_json("all_regression_results.json", orient="records", indent=2, force_ascii=False)
        
        # CrÃ©er un rÃ©sumÃ© par nature
        summary = []
        for nature_id in combined_results["Nature_ID"].unique():
            nature_results = combined_results[combined_results["Nature_ID"] == nature_id]
            best_model = nature_results.iloc[0]
            summary.append({
                "Nature_ID": nature_id,
                "Best_Model": best_model["Model"],
                "Best_RMSE": best_model["RMSE"],
                "Best_R2": best_model["RÂ² Score"],
                "Total_Data": best_model["Total_Data"]
            })
        
        summary_df = pd.DataFrame(summary).sort_values(by="Best_RMSE")
        summary_df.to_json("regression_summary.json", orient="records", indent=2, force_ascii=False)
        
        print(f"\nâœ… RÃ©sultats sauvegardÃ©s:")
        print(f"   ðŸ“ RÃ©sultats par nature: nature_X/regression_results.json")
        print(f"   ðŸ“Š RÃ©sultats combinÃ©s: all_regression_results.json")
        print(f"   ðŸ“ˆ RÃ©sumÃ©: regression_summary.json")
        
        print(f"\nðŸ“Š RÃ‰SUMÃ‰ GLOBAL:")
        print(f"   ðŸ“ Natures traitÃ©es: {processed_count}")
        print(f"   âŒ Erreurs: {error_count}")
        print(f"   ðŸ† Meilleur modÃ¨le global: {summary_df.iloc[0]['Best_Model']} (RMSE: {summary_df.iloc[0]['Best_RMSE']})")
        
        # Afficher le top 5 des meilleures natures
        print(f"\nðŸ† TOP 5 DES MEILLEURES NATURES:")
        for i, row in summary_df.head().iterrows():
            print(f"   {i+1}. Nature {row['Nature_ID']}: {row['Best_Model']} (RMSE: {row['Best_RMSE']}, RÂ²: {row['Best_R2']:.4f})")
    
    return combined_results if all_results else None

if __name__ == "__main__":
    process_all_natures()
